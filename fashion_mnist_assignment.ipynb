{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABBAS-37405/PYTHON-AND-DATA-SCIENCE/blob/main/fashion_mnist_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSOR FLOW ML MODEL\n",
        "1ï¸âƒ£ What is TensorFlow? (Very Basic)\n",
        "\n",
        "TensorFlow is a Python library used to build Machine Learning (ML) and Deep Learning (DL) models.\n",
        "\n",
        "ğŸ“Œ In simple words:\n",
        "\n",
        "TensorFlow helps computers learn from data and make predictions.\n",
        "\n",
        "Examples of what TensorFlow is used for:\n",
        "\n",
        "Image recognition ğŸ“·\n",
        "\n",
        "Voice recognition ğŸ¤\n",
        "\n",
        "Text prediction (like ChatGPT) ğŸ’¬\n",
        "\n",
        "Price prediction ğŸ“ˆ\n",
        "\n",
        "2ï¸âƒ£ Why the name â€œTensorFlowâ€?\n",
        "\n",
        "Tensor â†’ multi-dimensional data (numbers in arrays)\n",
        "\n",
        "Flow â†’ how data moves through computations\n",
        "\n",
        "ğŸ‘‰ So TensorFlow = flow of tensors through operations\n",
        "\n",
        "3ï¸âƒ£ What is a Tensor? (Most Important)\n",
        "\n",
        "A tensor is just a container for numbers.\n",
        "\n",
        "Data Type\tExample\tTensor Rank\n",
        "Scalar\t5\t0D\n",
        "Vector\t[1, 2, 3]\t1D\n",
        "Matrix\t[[1,2],[3,4]]\t2D\n",
        "3D Tensor\tImage data\t3D\n",
        "\n",
        "ğŸ“Œ Example:\n",
        "\n",
        "5              â†’ scalar\n",
        "[1, 2, 3]      â†’ vector\n",
        "[[1,2],[3,4]]  â†’ matrix\n",
        "\n",
        "4ï¸âƒ£ Installing TensorFlow\n",
        "pip install tensorflow\n",
        "\n",
        "\n",
        "Check version:\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "5ï¸âƒ£ First TensorFlow Example (Very Simple)\n",
        "Create a tensor\n",
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(5)\n",
        "b = tf.constant(3)\n",
        "\n",
        "c = a + b\n",
        "print(c)\n",
        "\n",
        "\n",
        "ğŸ” Output:\n",
        "\n",
        "tf.Tensor(8, shape=(), dtype=int32)\n",
        "\n",
        "\n",
        "ğŸ“Œ TensorFlow does math using tensors, not simple numbers.\n",
        "\n",
        "6ï¸âƒ£ TensorFlow vs NumPy (Simple Comparison)\n",
        "Feature\tNumPy\tTensorFlow\n",
        "Speed\tFast\tFaster (GPU/TPU)\n",
        "ML Models\tâŒ\tâœ…\n",
        "Automatic Gradient\tâŒ\tâœ…\n",
        "\n",
        "ğŸ‘‰ TensorFlow is designed for learning models, NumPy is not.\n",
        "\n",
        "7ï¸âƒ£ Building a Simple Machine Learning Model\n",
        "Problem:\n",
        "\n",
        "ğŸ‘‰ Predict y = 2x\n",
        "\n",
        "Step 1: Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "Step 2: Prepare data\n",
        "x = [1, 2, 3, 4]\n",
        "y = [2, 4, 6, 8]\n",
        "\n",
        "Step 3: Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "\n",
        "ğŸ“Œ This means:\n",
        "\n",
        "1 input\n",
        "\n",
        "1 output\n",
        "\n",
        "One neuron\n",
        "\n",
        "Step 4: Compile the model\n",
        "model.compile(\n",
        "    optimizer='sgd',\n",
        "    loss='mean_squared_error'\n",
        ")\n",
        "\n",
        "\n",
        "optimizer â†’ how model learns\n",
        "\n",
        "loss â†’ how wrong the prediction is\n",
        "\n",
        "Step 5: Train the model\n",
        "model.fit(x, y, epochs=500)\n",
        "\n",
        "\n",
        "ğŸ“Œ epochs = number of learning rounds\n",
        "\n",
        "Step 6: Test prediction\n",
        "print(model.predict([10]))\n",
        "\n",
        "\n",
        "ğŸ” Output (approx):\n",
        "\n",
        "[[20.0]]\n",
        "\n",
        "\n",
        "ğŸ‰ The model learned y = 2x\n",
        "\n",
        "8ï¸âƒ£ What Happened Behind the Scenes?\n",
        "\n",
        "Model guessed random values\n",
        "\n",
        "Calculated error (loss)\n",
        "\n",
        "Updated weights\n",
        "\n",
        "Repeated until error became small\n",
        "\n",
        "This process is called training.\n",
        "\n",
        "9ï¸âƒ£ Important TensorFlow Concepts (Beginner List)\n",
        "\n",
        "Tensor\n",
        "\n",
        "Model\n",
        "\n",
        "Layers\n",
        "\n",
        "Weights\n",
        "\n",
        "Loss function\n",
        "\n",
        "Optimizer\n",
        "\n",
        "Epoch\n",
        "\n",
        "Prediction\n",
        "\n",
        "ğŸ”Ÿ Real-Life Example (Simple)\n",
        "Input\tOutput\n",
        "House size\tHouse price\n",
        "Temperature\tIce cream sales\n",
        "Study hours\tExam marks\n",
        "\n",
        "TensorFlow finds the relationship between input & output.\n",
        "\n",
        "1ï¸âƒ£1ï¸âƒ£ Deep Learning in TensorFlow (Short Intro)\n",
        "\n",
        "If we add more layers, it becomes Deep Learning:\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "ğŸ“Œ Used for:\n",
        "\n",
        "Images\n",
        "\n",
        "Audio\n",
        "\n",
        "Text\n",
        "\n",
        "AI models\n",
        "\n",
        "1ï¸âƒ£2ï¸âƒ£ Summary (Easy Words)\n",
        "\n",
        "âœ” TensorFlow is for AI & ML\n",
        "âœ” It works on tensors\n",
        "âœ” Models learn by reducing errors\n",
        "âœ” Used in real-world AI systems"
      ],
      "metadata": {
        "id": "1vwffZrFpq91"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ec9036b"
      },
      "source": [
        "### Step 1: Data Loading\n",
        "\n",
        "This first step is all about getting our data ready. We're using the `fashion_mnist` dataset, which is a collection of small images of clothing items like shirts, shoes, and bags.\n",
        "\n",
        "*   `import tensorflow as tf` and `from tensorflow.keras.datasets import fashion_mnist`: These lines bring in the necessary tools from TensorFlow and Keras to work with machine learning models and datasets.\n",
        "*   `(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()`: This is where we load the dataset. It's automatically split into four parts:\n",
        "    *   `x_train`: These are the 60,000 images we'll use to **train** our model.\n",
        "    *   `y_train`: These are the labels (e.g., 'T-shirt', 'trouser') for each of the `x_train` images.\n",
        "    *   `x_test`: These are 10,000 new images the model hasn't seen before, which we'll use to **test** how well it learned.\n",
        "    *   `y_test`: These are the correct labels for the `x_test` images.\n",
        "*   `print(\"Training data shape:\", x_train.shape)` and `print(\"Testing data shape:\", x_test.shape)`: These lines show us the size and structure of our image data. For example, `(60000, 28, 28)` means there are 60,000 images, and each image is 28 pixels tall and 28 pixels wide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "274c476c"
      },
      "source": [
        "### Step 2: Data Preprocessing\n",
        "\n",
        "Before feeding the images to our neural network, we need to do a little preparation:\n",
        "\n",
        "*   `x_train = x_train / 255.0` and `x_test = x_test / 255.0`: Image pixel values typically range from 0 to 255 (representing black to white, or different color intensities). We divide them by 255.0 to scale them down to a range between 0 and 1. This normalization helps the neural network learn more efficiently.\n",
        "*   `x_train = x_train.reshape(-1, 784)` and `x_test = x_test.reshape(-1, 784)`: Each image is currently a 28x28 grid of pixels. Neural networks like the one we're building often prefer a flat list of numbers as input. So, we \"flatten\" each 28x28 image into a single long list of 784 numbers (28 * 28 = 784). The `-1` tells Python to figure out the number of images automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f7e68d3"
      },
      "source": [
        "### Step 3: Model Development (Building the Neural Network)\n",
        "\n",
        "Now, let's build the brain of our model â€“ the neural network!\n",
        "\n",
        "*   `model = tf.keras.Sequential([...])`: This creates a \"sequential\" model, meaning we're stacking layers one after another. Think of it like a chain of processing steps.\n",
        "*   `tf.keras.layers.Dense(...)`: These are our main building blocks, called \"dense\" or \"fully connected\" layers. Each neuron in a dense layer is connected to every neuron in the previous layer.\n",
        "    *   `input_shape=(784,)`: This is specified only in the *first* dense layer and tells the model that each input image will be a flattened array of 784 pixels.\n",
        "    *   `32`, `64`, `128`: These numbers indicate how many \"neurons\" or processing units are in each hidden layer. More neurons can help the model learn more complex patterns.\n",
        "    *   `10`: The *last* dense layer has 10 neurons because there are 10 different categories of clothing in our dataset (e.g., T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot).\n",
        "    *   `activation='relu'`: This is an \"activation function.\" After a neuron processes its input, the activation function decides whether it should \"fire\" or not. 'relu' (Rectified Linear Unit) is a common choice for hidden layers because it's computationally efficient.\n",
        "    *   `activation='softmax'`: This is used in the *final* layer. It converts the output of the 10 neurons into probabilities, where all probabilities add up to 1. The class with the highest probability is what the model predicts.\n",
        "    *   `kernel_initializer='glorot_uniform'`: This specifies how the initial weights of the network are set. Good initialization can help the model learn faster and more effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "857a670f"
      },
      "source": [
        "### Step 4: Model Compilation\n",
        "\n",
        "After building the model's structure, we need to \"compile\" it. This is like configuring how the model will learn.\n",
        "\n",
        "*   `model.compile(...)`: This prepares the model for training.\n",
        "*   `optimizer=tf.keras.optimizers.Adam()`: The \"optimizer\" is the algorithm that adjusts the model's internal weights to minimize errors. Adam is a popular and effective choice.\n",
        "*   `loss='sparse_categorical_crossentropy'`: The \"loss function\" measures how far off our model's predictions are from the true labels. `sparse_categorical_crossentropy` is suitable for classification problems where each input belongs to a single category, and the labels are integers (0, 1, 2,...).\n",
        "*   `metrics=['accuracy']`: During training and evaluation, we want to keep an eye on how well the model is performing. 'accuracy' tells us the percentage of correctly classified images.\n",
        "*   `model.summary()`: This prints a helpful summary of our model, showing each layer, its output shape, and the number of parameters (weights and biases) it contains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f26768f5"
      },
      "source": [
        "### Step 5: Model Training and Evaluation\n",
        "\n",
        "Finally, we train our model and see how well it performs.\n",
        "\n",
        "*   `history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.1)`:\n",
        "    *   `model.fit()`: This is where the actual training happens. The model learns from the `x_train` images and `y_train` labels.\n",
        "    *   `epochs=20`: An \"epoch\" means the model goes through the *entire* training dataset once. We're doing this 20 times to allow the model to learn iteratively.\n",
        "    *   `batch_size=32`: Instead of feeding all 60,000 images at once, the model processes them in smaller groups (batches) of 32 images. This helps with computational efficiency.\n",
        "    *   `validation_split=0.1`: We reserve 10% of the training data (6,000 images) as a \"validation set.\" The model does *not* train on this data, but it uses it to check its performance during training. This helps us see if the model is learning well or if it's starting to \"memorize\" the training data (overfitting).\n",
        "\n",
        "*   `test_loss, test_accuracy = model.evaluate(x_test, y_test)`:\n",
        "    *   `model.evaluate()`: After training, we evaluate the model's performance on the completely unseen `x_test` images and `y_test` labels.\n",
        "    *   `test_loss`: This is the value of the loss function on the test set, indicating how many errors the model made.\n",
        "    *   `test_accuracy`: This is the accuracy of the model on the test set. It's the most important metric to see how well our model generalizes to new data.\n",
        "*   `print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))`: This line simply prints the final test accuracy as a percentage. In this case, the model achieved about 88.04% accuracy on the test data, which is a good result!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**"
      ],
      "metadata": {
        "id": "nLMgm_4u6top"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ca002GQ1vaTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3aac558-6cd7-4f25-8277-b963b335c04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape: (60000, 28, 28)\n",
            "Testing data shape: (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion MNIST data (already split into train and test sets)\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Check the shape of the data\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "CHerZl4r60In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train /255.0\n",
        "x_test = x_test /255.0\n",
        "# Reshape data to add a channel dimension\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)"
      ],
      "metadata": {
        "id": "DnTVSgfXvisA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Development**"
      ],
      "metadata": {
        "id": "ffHZwUKO672V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', kernel_initializer='glorot_uniform', input_shape=(784,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax',kernel_initializer='glorot_uniform')\n",
        "])"
      ],
      "metadata": {
        "id": "h3VNxm4f6yHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98113e3-3ecb-4381-ffe4-b549eaf2b5fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# View model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yn3U7jXm67FB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1b0f54c8-89e7-4af2-d684-495a776df2eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚        \u001b[38;5;34m25,120\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m2,112\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,290\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,842\u001b[0m (143.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,842</span> (143.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,842\u001b[0m (143.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,842</span> (143.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=32,validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ],
      "metadata": {
        "id": "WeN6ytUy7CfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6627f34d-2521-4446-e19c-f85f8fed3626"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.7254 - val_accuracy: 0.8500 - val_loss: 0.4118\n",
            "Epoch 2/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.4016 - val_accuracy: 0.8542 - val_loss: 0.4039\n",
            "Epoch 3/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3573 - val_accuracy: 0.8690 - val_loss: 0.3703\n",
            "Epoch 4/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.3344 - val_accuracy: 0.8723 - val_loss: 0.3455\n",
            "Epoch 5/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.3189 - val_accuracy: 0.8740 - val_loss: 0.3388\n",
            "Epoch 6/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.3038 - val_accuracy: 0.8612 - val_loss: 0.3737\n",
            "Epoch 7/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2872 - val_accuracy: 0.8740 - val_loss: 0.3583\n",
            "Epoch 8/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8951 - loss: 0.2759 - val_accuracy: 0.8788 - val_loss: 0.3356\n",
            "Epoch 9/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2694 - val_accuracy: 0.8773 - val_loss: 0.3391\n",
            "Epoch 10/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2642 - val_accuracy: 0.8808 - val_loss: 0.3292\n",
            "Epoch 11/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2560 - val_accuracy: 0.8872 - val_loss: 0.3198\n",
            "Epoch 12/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2508 - val_accuracy: 0.8780 - val_loss: 0.3526\n",
            "Epoch 13/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2405 - val_accuracy: 0.8827 - val_loss: 0.3431\n",
            "Epoch 14/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2435 - val_accuracy: 0.8812 - val_loss: 0.3400\n",
            "Epoch 15/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2374 - val_accuracy: 0.8733 - val_loss: 0.3502\n",
            "Epoch 16/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2291 - val_accuracy: 0.8845 - val_loss: 0.3490\n",
            "Epoch 17/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2256 - val_accuracy: 0.8852 - val_loss: 0.3414\n",
            "Epoch 18/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2239 - val_accuracy: 0.8863 - val_loss: 0.3451\n",
            "Epoch 19/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2177 - val_accuracy: 0.8822 - val_loss: 0.3528\n",
            "Epoch 20/20\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2133 - val_accuracy: 0.8870 - val_loss: 0.3609\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3780\n",
            "Test Accuracy: 88.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXUVdZAW7Fcc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}