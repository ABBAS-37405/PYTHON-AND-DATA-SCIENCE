{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABBAS-37405/PYTHON-AND-DATA-SCIENCE/blob/main/XGBoost_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost Classifier**"
      ],
      "metadata": {
        "id": "JMfwTWL-UifI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost (eXtreme Gradient Boosting) is a powerful and popular open-source machine learning algorithm that is known for its speed and performance. It's an implementation of gradient-boosted decision trees, designed to be highly efficient, flexible, and portable. Here are some key aspects:\n",
        "\n",
        "Gradient Boosting: XGBoost is built on the concept of gradient boosting, where new models are created that predict the residuals or errors of previous models and then added together to make the final prediction.\n",
        "Decision Trees: The 'base learners' in XGBoost are typically decision trees, which are simple, tree-like structures used for classification and regression.\n",
        "Regularization: It includes various regularization techniques (L1 and L2 regularization) to prevent overfitting, which helps in improving generalization performance.\n",
        "Parallel Processing: XGBoost is optimized for parallel processing, making it significantly faster than other gradient boosting implementations, especially on large datasets.\n",
        "Flexibility: It can handle various types of data and problems, including classification, regression, and ranking.\n",
        "In essence, XGBoost combines many weak prediction models (decision trees) to create a stronger, more accurate predictive model, while also incorporating techniques to make the process fast and prevent the model from becoming too complex."
      ],
      "metadata": {
        "id": "N-wiPHaflT7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS9I2P29Ue1f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"healthcare_data_10000.csv\")\n",
        "\n",
        "# Encode target: Low = 0, High = 1\n",
        "df['health_risk_category'] = df['health_risk_category'].map({'Low': 0, 'High': 1})\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=['health_risk_category'])\n",
        "y = df['health_risk_category']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fccQk99UUloR",
        "outputId": "ceec362f-fb6a-4527-b67a-68431fa7f0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\\\n",
        "\n",
        "model = XGBClassifier(n_estimators = 100, learning_rate = 0.1, eval_metric = 'logloss', random_state = 42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "classification_report = classification_report(y_pred, y_test, target_names= ['Low', \"High\"])\n",
        "print(classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS0dv1zC-scJ",
        "outputId": "0cbd1fcb-5777-434c-ff16-f720b5af99e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Low       1.00      1.00      1.00      1736\n",
            "        High       1.00      0.99      1.00       264\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost Regressor**"
      ],
      "metadata": {
        "id": "xTJLejxCUl1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Select numeric columns\n",
        "numeric_cols = [\n",
        "    'age', 'bmi', 'systolic_bp', 'diastolic_bp',\n",
        "    'cholesterol_level', 'glucose_level',\n",
        "    'exercise_mins_per_week', 'alcohol_units_per_week', 'medications_count'\n",
        "]\n",
        "target = 'heart_rate'\n",
        "\n",
        "# Step 3: Feature matrix (X) and target vector (y)\n",
        "X = df[numeric_cols]\n",
        "y = df[target]\n",
        "\n",
        "# Step 4: Train-test split\n",
        "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 5: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8VNNGTlxUotN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "model = XGBRegressor(n_estimators = 100, learning_rate = 0.1, random_state = 42)\n",
        "model.fit(X_train_scaled, y_train_reg)\n",
        "\n",
        "y_pred_reg = model.predict(X_test_scaled)\n",
        "\n",
        "mean_squared_error = mean_squared_error(y_pred_reg, y_test_reg)\n",
        "RMSE = np.sqrt(mean_squared_error)\n",
        "print(RMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q57LFu6nUpO5",
        "outputId": "8041667c-06a1-4fdc-80d0-beae7408dab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.361777831016063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTUTqXWJUpRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}